{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de contenidos<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introducción\" data-toc-modified-id=\"Introducción-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introducción</a></span></li><li><span><a href=\"#Proyecto\" data-toc-modified-id=\"Proyecto-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Proyecto</a></span><ul class=\"toc-item\"><li><span><a href=\"#Descarga-y-preparacion-de-los-datos.\" data-toc-modified-id=\"Descarga-y-preparacion-de-los-datos.-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Descarga y preparacion de los datos.</a></span></li></ul></li><li><span><a href=\"#Examinamos-el-equilibrio-de-clases\" data-toc-modified-id=\"Examinamos-el-equilibrio-de-clases-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Examinamos el equilibrio de clases</a></span></li><li><span><a href=\"#Mejoramos-la-calidad-del-modelo-y-realizamos-pruebas-finales\" data-toc-modified-id=\"Mejoramos-la-calidad-del-modelo-y-realizamos-pruebas-finales-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Mejoramos la calidad del modelo y realizamos pruebas finales</a></span></li><li><span><a href=\"#Conclusion-y-test.\" data-toc-modified-id=\"Conclusion-y-test.-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Conclusion y test.</a></span><ul class=\"toc-item\"><li><span><a href=\"#Conclusiones-del-proyecto\" data-toc-modified-id=\"Conclusiones-del-proyecto-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Conclusiones del proyecto</a></span><ul class=\"toc-item\"><li><span><a href=\"#Metricas-con-el-conjunto-de-validacion:\" data-toc-modified-id=\"Metricas-con-el-conjunto-de-validacion:-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Metricas con el conjunto de validacion:</a></span></li><li><span><a href=\"#Metricas-con-el-conjunto-de-test:\" data-toc-modified-id=\"Metricas-con-el-conjunto-de-test:-5.1.2\"><span class=\"toc-item-num\">5.1.2&nbsp;&nbsp;</span>Metricas con el conjunto de test:</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "Los clientes de Beta Bank se están yendo, cada mes, poco a poco. Los banqueros descubrieron que es más barato salvar a los clientes existentes que atraer nuevos. Por lo que necesitamos predecir si un cliente dejará el banco pronto. Tenemos los datos sobre el comportamiento pasado de los clientes y la terminación de contratos con el banco.\n",
    "\n",
    "Crearemos un modelo con el máximo valor F1 posible. Tenemos como meta que el valor F1 de al menos 0.59. Verificaremos el valor F1 para el conjunto de pruebas. Además mediremos la métrica AUC-ROC y compararla con el valor F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proyecto\n",
    "\n",
    "- Comenzamos importando las librerias que utilizaremos para realizar el proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerias iniciales\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "#Librerias de Modelos y entrenamiento\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#Librerias de metricas\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descarga y preparacion de los datos.\n",
    "\n",
    "- Leemos el dataset que utilizaremos en el proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_betaBank_client=pandas.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_betaBank_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comprobamos los datos nulos del DataFrame.\n",
      "RowNumber            0\n",
      "CustomerId           0\n",
      "Surname              0\n",
      "CreditScore          0\n",
      "Geography            0\n",
      "Gender               0\n",
      "Age                  0\n",
      "Tenure             909\n",
      "Balance              0\n",
      "NumOfProducts        0\n",
      "HasCrCard            0\n",
      "IsActiveMember       0\n",
      "EstimatedSalary      0\n",
      "Exited               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Comprobamos los datos nulos del DataFrame.')\n",
    "print(df_betaBank_client.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comprobamos los datos duplicados en el dataset.\n",
      "El dataset tiene 0 filas duplicadas.\n"
     ]
    }
   ],
   "source": [
    "print('Comprobamos los datos duplicados en el dataset.')\n",
    "print('El dataset tiene',df_betaBank_client.duplicated().sum(),'filas duplicadas.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que no tenemos filas duplicadas pero si datos ausentes por lo que prepararemos la columna 'Tenure',que corresponde al período durante el cual ha madurado el depósito a plazo fijo de un cliente(años) para tener un DataFrame completo con el que podremos trabajar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  1.  8.  7.  4.  6.  3. 10.  5.  9.  0. nan]\n"
     ]
    }
   ],
   "source": [
    "print(df_betaBank_client['Tenure'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos 2 opciones que podemos elegir a la hora de decidir que hacer con los datos ausentes:\n",
    "- Podemos utilizar el promedio obtenido de los datos existentes y remplezar los datos ausentes con el promedio, ya que estamos hablando de periodos de maduracion de un deposito a plazo.\n",
    "\n",
    "- Podemos remplazar los datos ausentes por 0 ya que podemos entender que no han tenido un periodo de maduracion en depositos a plazos.\n",
    "\n",
    "Eligiremos la 2da opción ya que rellenar con datos inciertos en lo que es depositos a plazos puede suponer un problema para el banco si es que no corresponde al tiempo de antiguedad del cliente o a otros factores, en cambio, como son datos nulos podemos entender que existen y comprenderlo como un periodo de tiempo igual a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_betaBank_client['Tenure']=df_betaBank_client['Tenure'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comprobamos los datos nulos del DataFrame.\n",
      "RowNumber          0\n",
      "CustomerId         0\n",
      "Surname            0\n",
      "CreditScore        0\n",
      "Geography          0\n",
      "Gender             0\n",
      "Age                0\n",
      "Tenure             0\n",
      "Balance            0\n",
      "NumOfProducts      0\n",
      "HasCrCard          0\n",
      "IsActiveMember     0\n",
      "EstimatedSalary    0\n",
      "Exited             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Comprobamos los datos nulos del DataFrame.')\n",
    "print(df_betaBank_client.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El DataFrame ya esta completo, pero nos queda limpiarlo para poder dividirlo en los conjuntos de entrenamiento, validación y testeo, para eso eliminaremos las 3 primeras columnas:\n",
    "\n",
    "- RowNumber: índice de cadena de datos\n",
    "- CustomerId: identidicador de cliente único\n",
    "- Surname: apellido\n",
    "\n",
    "Estas columnas se consideran no relevantes a la hora de determinar si un cliente dejara el banco pronto o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  int64  \n",
      " 1   Geography        10000 non-null  object \n",
      " 2   Gender           10000 non-null  object \n",
      " 3   Age              10000 non-null  int64  \n",
      " 4   Tenure           10000 non-null  float64\n",
      " 5   Balance          10000 non-null  float64\n",
      " 6   NumOfProducts    10000 non-null  int64  \n",
      " 7   HasCrCard        10000 non-null  int64  \n",
      " 8   IsActiveMember   10000 non-null  int64  \n",
      " 9   EstimatedSalary  10000 non-null  float64\n",
      " 10  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_betaBank_client=df_betaBank_client.drop(['RowNumber','CustomerId','Surname'], axis=1)\n",
    "df_betaBank_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_betaBank_client['Exited'].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que tenemos un desbalance en la clase ya que tenemos más valores 0 que 1 y una clase balanceada debe estar en una razon de 1:1, recordemos que la columna 'Exited' nos dice si el cliente se ha ido (1 - sí; 0 - no), por lo que podemos entender que al modelo le será dificil identificar los clientes que si se fueron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  float64\n",
      " 1   Geography        10000 non-null  float64\n",
      " 2   Age              10000 non-null  float64\n",
      " 3   Tenure           10000 non-null  float64\n",
      " 4   Balance          10000 non-null  float64\n",
      " 5   NumOfProducts    10000 non-null  float64\n",
      " 6   EstimatedSalary  10000 non-null  float64\n",
      " 7   Gender           10000 non-null  float64\n",
      " 8   HasCrCard        10000 non-null  float64\n",
      " 9   IsActiveMember   10000 non-null  float64\n",
      " 10  Exited           10000 non-null  float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 859.5 KB\n"
     ]
    }
   ],
   "source": [
    "# Realizamos la codificacion a nuestro dataFrame\n",
    "encoder = OrdinalEncoder()\n",
    "data_transformed = pandas.DataFrame(encoder.fit_transform(df_betaBank_client), columns=df_betaBank_client.columns)\n",
    "\n",
    "# Estandarizamos los datos con el StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Realizamos el metodo solo en las columnas no binarias resultantes del encoder\n",
    "data=data_transformed.drop(['Gender','HasCrCard','IsActiveMember','Exited'], axis=1)\n",
    "data=pandas.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "\n",
    "# Eliminamos las columnas del DataFrame original para ser remplazadas por los datos estandarrizados.\n",
    "data_transformed = data_transformed.drop(['CreditScore','Geography','Age','Tenure','Balance','NumOfProducts','EstimatedSalary'], axis=1)\n",
    "data_transformed = pandas.concat([data,data_transformed],axis=1)\n",
    "\n",
    "# Verificamos el nuevo DataFrame\n",
    "data_transformed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora nuestro DataFrame no tiene datos duplicados ni ausentes por lo que podemos comenzar a trabajar con el sin ningun inconveniente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examinamos el equilibrio de clases\n",
    "\n",
    "- En primera instancia entrenaremos un modelo sin tener en cuenta el desequilibrio, para eso comenzaremos primero realizando los conjuntos de entrenamiento y validacion para posteriormente crear el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos el conjunto de 'test' y dejamos otro conjunto llamado 'rest'.\n",
    "rest,test=train_test_split(data_transformed,test_size=0.2,random_state=54321)\n",
    "\n",
    "# Del conjunto 'rest' obtendemos el conjunto de entrenamiento y validacion.\n",
    "train,valid=train_test_split(rest,test_size=0.25,random_state=54321)\n",
    "\n",
    "#Entrenamiento\n",
    "features_train=train.drop(['Exited'],axis=1)\n",
    "target_train=train['Exited']\n",
    "#Validacion\n",
    "features_valid=valid.drop(['Exited'],axis=1)\n",
    "target_valid= valid['Exited']\n",
    "#Prueba\n",
    "features_test=test.drop(['Exited'],axis=1)\n",
    "target_test=test['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaramos variables para medir mce y exactitud de los modelos.\n",
    "best_depth=0\n",
    "best_f1=0\n",
    "best_score=0\n",
    "for depth in range(1,11): # Seleccionamos el rango del hiperparámetro.\n",
    "    model_tree= DecisionTreeClassifier(max_depth=depth,random_state=12345) # Declaramos el modelo.\n",
    "    model_tree.fit(features_train,target_train) # Entrenamos el modelo en el conjunto de entrenamiento.\n",
    "    predictions_valid = model_tree.predict(features_valid) # Obtenemos las predicciones del modelo en el conjunto de validación.\n",
    "    probabilities_valid= model_tree.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    score= model_tree.score(features_test,target_test) # Calculamos la puntuacion de accuracy en el conjunto de test.\n",
    "    f1=f1_score(target_valid, predictions_valid)\n",
    "    if score>best_score:\n",
    "        best_score=score # Guardamos la mejor puntuacion de accurracy en el conjunto de validación.  \n",
    "    if f1 > best_f1:\n",
    "        best_f1=f1\n",
    "        best_depth=depth\n",
    "        auc_roc=roc_auc_score(target_valid,probabilities_one_valid)\n",
    "        confusion=confusion_matrix(target_valid, predictions_valid)\n",
    "        recall=recall_score(target_valid, predictions_valid)\n",
    "        precision=precision_score(target_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La mejor profundidad es: 9\n",
      "La exactitud del mejor modelo en el conjunto de pruebas es de : 0.866\n"
     ]
    }
   ],
   "source": [
    "print(\"La mejor profundidad es:\", best_depth)\n",
    "print(\"La exactitud del mejor modelo en el conjunto de pruebas es de : {}\".format(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La matriz de confusion para el modelo de arbol de clasificación es:\n",
      "[[1463   95]\n",
      " [ 237  205]]\n",
      "La proporcion de respuestas VP(verdaderas positivas) es: 0.4638009049773756\n",
      "La cantidad de respuestas negativas encontro el modelo mientras buscaba respuestas positivas es 0.6833333333333333\n",
      "El valor de la metrica F1 es: 0.5421052631578948\n"
     ]
    }
   ],
   "source": [
    "print('La matriz de confusion para el modelo de arbol de clasificación es:')\n",
    "print(confusion)\n",
    "print('La proporcion de respuestas VP(verdaderas positivas) es:',recall)\n",
    "print('La cantidad de respuestas negativas encontro el modelo mientras buscaba respuestas positivas es',precision)\n",
    "print('El valor de la metrica F1 es:',f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejoramos la calidad del modelo y realizamos pruebas finales\n",
    "\n",
    "- Probaremos con el modelo de bosque aleatorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Declaramos variables para exactitud de los modelos.\n",
    "best_depth=0\n",
    "best_f1=0\n",
    "best_est_score=0\n",
    "best_score=0\n",
    "for est in range(5,30,5): # Entrenaremos 20 modelos en intervalos de 5\n",
    "    for depth in range (1,11): # La profundidad de los arboles sera de 1 a 5\n",
    "        model_forest=RandomForestClassifier(random_state=12345,n_estimators=est, max_depth=depth) # Configuramos el numero de arboles.\n",
    "        model_forest.fit(features_train,target_train) # Entrenamos el modelo con el conjunto de entrenamiento.\n",
    "        predictions_valid= model_forest.predict(features_valid) # Realizamos prediciones con el conjunto de validación.\n",
    "        probabilities_valid = model_forest.predict_proba(features_valid)\n",
    "        probabilities_one_valid = probabilities_valid[:, 1]\n",
    "        score= model_forest.score(features_test,target_test) # Calculamos la puntuacion de accuracy en el conjunto de test.\n",
    "        if score>best_score:\n",
    "            best_score=score # Guardamos la mejor puntuacion de accurracy en el conjunto de validación.\n",
    "            best_est_score=est # Guardamos el número de estimadores que corresponden a la mejor punturación de exactitud.\n",
    "        if f1>best_f1:\n",
    "            best_depth= depth # Guardamos la mejor profundidad para los arboles del bosque.\n",
    "            best_f1=f1\n",
    "            auc_roc=roc_auc_score(target_valid,probabilities_one_valid)\n",
    "            confusion=confusion_matrix(target_valid, predictions_valid)\n",
    "            recall=recall_score(target_valid, predictions_valid)\n",
    "            precision=precision_score(target_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La mejor profundidad es: 1\n",
      "La exactitud del mejor modelo en el conjunto de pruebas con n_estimators(estimadores) 25) es de : 0.875\n"
     ]
    }
   ],
   "source": [
    "print(\"La mejor profundidad es:\", best_depth)\n",
    "print(\"La exactitud del mejor modelo en el conjunto de pruebas con n_estimators(estimadores) {}) es de : {}\".format(best_est_score, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La matriz de confusion para el modelo de arbol de clasificación es:\n",
      "[[1558    0]\n",
      " [ 442    0]]\n",
      "La proporcion de respuestas VP(verdaderas positivas) es: 0.0\n",
      "La cantidad de respuestas negativas encontro el modelo mientras buscaba respuestas positivas es 0.0\n",
      "El valor de la metrica F1 es: 0.5421052631578948\n"
     ]
    }
   ],
   "source": [
    "print('La matriz de confusion para el modelo de arbol de clasificación es:')\n",
    "print(confusion)\n",
    "print('La proporcion de respuestas VP(verdaderas positivas) es:',recall)\n",
    "print('La cantidad de respuestas negativas encontro el modelo mientras buscaba respuestas positivas es',precision)\n",
    "print('El valor de la metrica F1 es:',f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ahora probaremos con un modelo de regresion logistica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logistic = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model_logistic.fit(features_train, target_train)\n",
    "predictions_valid = model_logistic.predict(features_valid) # Obtenemos las predicciones del modelo en el conjunto de validación.\n",
    "score= model_logistic.score(features_test,target_test) # Calculamos la puntuacion de accuracy en el conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del mejor modelo en el conjunto de pruebas es de : 0.875\n"
     ]
    }
   ],
   "source": [
    "print(\"La exactitud del mejor modelo en el conjunto de pruebas es de : {}\".format(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_valid = model_logistic.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc=roc_auc_score(target_valid,probabilities_one_valid)\n",
    "confusion=confusion_matrix(target_valid, predictions_valid)\n",
    "recall=recall_score(target_valid, predictions_valid)\n",
    "precision=precision_score(target_valid, predictions_valid)\n",
    "f1=f1_score(target_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La matriz de confusion para el modelo de arbol de clasificación es:\n",
      "[[1518   40]\n",
      " [ 376   66]]\n",
      "La proporcion de respuestas VP(verdaderas positivas) es: 0.1493212669683258\n",
      "La cantidad de respuestas negativas encontro el modelo mientras buscaba respuestas positivas es 0.6226415094339622\n",
      "El valor de la metrica F1 es: 0.24087591240875908\n"
     ]
    }
   ],
   "source": [
    "print('La matriz de confusion para el modelo de arbol de clasificación es:')\n",
    "print(confusion)\n",
    "print('La proporcion de respuestas VP(verdaderas positivas) es:',recall)\n",
    "print('La cantidad de respuestas negativas encontro el modelo mientras buscaba respuestas positivas es',precision)\n",
    "print('El valor de la metrica F1 es:',f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion y test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabiendo que el modelo con mejores metricas obtenidas fue el DecisionTreeClassifier realizamos el testeo con este modelo que corresponde utilizar el conjunto de test en vez de el de validacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos el modelo con mejores resultados pero ahora utilizaremos el conjunto de testeo en vez de validacion\n",
    "depth=9\n",
    "model_tree= DecisionTreeClassifier(max_depth=depth,random_state=12345) # Declaramos el modelo.\n",
    "model_tree.fit(features_train,target_train) # Entrenamos el modelo en el conjunto de entrenamiento.\n",
    "predictions_test = model_tree.predict(features_test) # Obtenemos las predicciones del modelo en el conjunto de test.\n",
    "probabilities_test= model_tree.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "score= model_tree.score(features_test,target_test) # Calculamos la puntuacion de accuracy en el conjunto de test.\n",
    "f1=f1_score(target_test, predictions_test)\n",
    "auc_roc=roc_auc_score(target_test,probabilities_one_test)\n",
    "confusion=confusion_matrix(target_test, predictions_test)\n",
    "recall=recall_score(target_test, predictions_test)\n",
    "precision=precision_score(target_test, predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La profundidad escogida es: 9\n",
      "La exactitud del modelo en el conjunto de pruebas es de : 0.8505\n",
      "La matriz de confusion para el modelo de arbol de clasificación es:\n",
      "[[1538   72]\n",
      " [ 227  163]]\n",
      "La proporcion de respuestas VP(verdaderas positivas) es: 0.41794871794871796\n",
      "La cantidad de respuestas negativas encontro el modelo mientras buscaba respuestas positivas es 0.6936170212765957\n",
      "El valor de la metrica F1 es: 0.5216000000000001\n"
     ]
    }
   ],
   "source": [
    "print(\"La profundidad escogida es:\",depth)\n",
    "print(\"La exactitud del modelo en el conjunto de pruebas es de : {}\".format(score))\n",
    "print('La matriz de confusion para el modelo de arbol de clasificación es:')\n",
    "print(confusion)\n",
    "print('La proporcion de respuestas VP(verdaderas positivas) es:',recall)\n",
    "print('La cantidad de respuestas negativas encontro el modelo mientras buscaba respuestas positivas es',precision)\n",
    "print('El valor de la metrica F1 es:',f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones del proyecto\n",
    "Como podemos observar tuvimos diferentes metricas por cada modelo de entrenamiento que realizamos, con el modelo que obtuvimos mejores resultados fue con el arbol de decisiones, aun que no pudimos alcanzar el valor de F1 deseado por la relacion entre los valores del recall y precision.\n",
    "\n",
    "Vamos a realizar un comparacion de los resultados obtenidos entre los conjuntos de validacion y test en lo que respecta el modelo de arbol de decisiones.\n",
    "\n",
    "#### Metricas con el conjunto de validacion:\n",
    "\n",
    "- La matriz de confusion para el modelo de arbol de clasificación es:\n",
    "\n",
    "[[1463   95]\n",
    "\n",
    " [ 237  205]]\n",
    "\n",
    "- La proporcion de respuestas VP(verdaderas positivas) es: 0.4638009049773756\n",
    "- La cantidad de respuestas negativas encontro el modelo mientras buscaba respuestas positivas es 0.6833333333333333\n",
    "- El valor de la metrica F1 es: 0.5421052631578948\n",
    "\n",
    "#### Metricas con el conjunto de test:\n",
    "\n",
    "- La matriz de confusion para el modelo de arbol de clasificación es:\n",
    "\n",
    "[[1538   72]\n",
    "\n",
    "[ 227  163]]\n",
    "\n",
    "- La proporcion de respuestas VP(verdaderas positivas) es: 0.41794871794871796\n",
    "- La cantidad de respuestas negativas encontro el modelo mientras buscaba respuestas positivas es 0.6936170212765957\n",
    "- El valor de la metrica F1 es: 0.5216000000000001"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de contenidos",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
